{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 4. Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (8 баллов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
    "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели. \n",
    "Можно использовать данные из семинара или любые другие (сопоставимые или большие по объему). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
    "\n",
    "\n",
    "Подсказки:  \n",
    "    - нужно будет добавить еще один тэг <start>  \n",
    "    - еще одна матрица не нужна, можно по строкам хронить биграмы, а по колонкам униграммы  \n",
    "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvach = open('data/2ch_corpus.txt', encoding='utf-8').read()\n",
    "news = open('data/lenta.txt', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0, len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dvach = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach)]\n",
    "sentences_news = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentences.extend(sentences_dvach)\n",
    "sentences.extend(sentences_news)\n",
    "sentences = [s.split() for s in set([' '.join(s) for s in sentences])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample = len(sentences)\n",
    "train_sentences = sentences[:max_sample - int(max_sample*0.2) - 1]\n",
    "test_sentences = random.sample(sentences[len(train_sentences) + 1:], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = Counter()\n",
    "bigrams  = Counter()\n",
    "trigrams = Counter()\n",
    "\n",
    "for sentence in train_sentences:\n",
    "    unigrams.update(sentence)\n",
    "    bigrams.update(ngrammer(sentence))\n",
    "    trigrams.update(ngrammer(sentence, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix = lil_matrix((len(bigrams), \n",
    "                         len(unigrams)),)\n",
    "rows = list(bigrams)\n",
    "rows_id = {bigram:i for i, bigram in enumerate(rows)}\n",
    "cols = list(unigrams)\n",
    "cols_id = {word:i for i, word in enumerate(cols)}\n",
    "\n",
    "for ngram in trigrams:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    all_matrix[rows_id[word1 + ' ' + word2], cols_id[word3]] =  (trigrams[ngram]/\n",
    "                                                                     bigrams[word1 + ' ' + word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, cols, rows, rows_id, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = rows_id[start]\n",
    "    for i in range(n):\n",
    "        chosen = np.random.choice(matrix.getrow(current_idx).toarray().shape[1], p=matrix.getrow(current_idx).toarray()[0])\n",
    "        text.append(cols[chosen])\n",
    "        if cols[chosen] == '<end>':\n",
    "            current_idx = rows_id[start]\n",
    "        else:\n",
    "            phrase = rows[current_idx] + ' ' + cols[chosen]\n",
    "            phrase = ' '.join(phrase.split()[1:])\n",
    "            current_idx = rows_id[phrase]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "чувак ты лучший \n",
      " часами напролет пиздели до рассвета среды \n",
      " в ходе которых он объявил жителям республики так и показал чему учился долгие годы считалась утраченной принадлежит родственнице покойного писателя василия кудашова друга михаила шолохова тихий дон найденная у частного лица будет приобретена другим известным производителем сигарет gauloises и gitanes крупнейшей табачной компанией франции \n",
      " почему у австралии совершенно не знаю какую то подставу \n",
      " я лично к саудитам ездил совещаться по этому делу задержаны 22 обвиняемых \n",
      " ты не понимаешь не о исламе ни о чём так приятно слушать потому что когда подписывался « минск-2 » дебальцевский район\n"
     ]
    }
   ],
   "source": [
    "print(generate(all_matrix, cols, rows, rows_id).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты генерации получаются не совсем осмысленные, но иногда получаются забавные предложения, которые соединяются с двачом и новостями. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(probas):\n",
    "    p = np.exp(np.sum(probas))\n",
    "    N = len(probas)\n",
    "    \n",
    "    return p**(-1/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: <start> <start> сложно оценивать <end>\n",
      "peplexity: 57399.977337743534\n",
      "sentence: <start> <start> каждая глава законченная мысль <end>\n",
      "peplexity: 63037.11262727307\n",
      "sentence: <start> <start> невынужденных ошибок что впрочем никак не помогло его сопернику <end>\n",
      "peplexity: 54861.75487023924\n",
      "sentence: <start> <start> это очень легко <end>\n",
      "peplexity: 44.37335394545081\n",
      "sentence: <start> <start> твой контролер просто изначально может выдавать 127 сюрприз но многие могут максимум 100-110 <end>\n",
      "peplexity: 80134.6638451409\n",
      "sentence: <start> <start> именно поэтому они отступили сконцентрировавшись на охране периметра и оставив всякую надежду управлять внутренним распорядком подопечных <end>\n",
      "peplexity: 43973.88657598156\n",
      "sentence: <start> <start> впервые об этом открыто сказал на прошлой неделе директор цру джордж тенет <end>\n",
      "peplexity: 3215.600324593135\n",
      "sentence: <start> <start> российский партнер телекомпании bloomberg канал нтв-плюс входит в холдинг медиа-мост и является первой в россии независимой спутниковой телекомпанией <end>\n",
      "peplexity: 7201.508123724757\n",
      "sentence: <start> <start> як жеж люди в ссср плодились чай не почкованием <end>\n",
      "peplexity: 106579.46019244795\n",
      "sentence: <start> <start> просто я чую тонкие флуктуации создаваемые инфополем <end>\n",
      "peplexity: 17353.053904371434\n",
      "sentence: <start> <start> мы своими телами крутим вами макаки как хотим <end>\n",
      "peplexity: 16.916897292125405\n",
      "sentence: <start> <start> других проектов по совместному огорождению питурдов от заебавшего социума я не знаю <end>\n",
      "peplexity: 20739.46633367962\n",
      "sentence: <start> <start> саммерс также заявил что в отношении бэнк оф нью-йорк на данный момент нет свидетельств того что какие-либо деньги мвф были использованы не по назначению <end>\n",
      "peplexity: 858.1070142961476\n",
      "sentence: <start> <start> определись уже к кому и с какой терминологией ты обращаешься своими аббревиатурами да ещё и в таком контексте <end>\n",
      "peplexity: 7252.33934844572\n",
      "sentence: <start> <start> по каким обвинениям <end>\n",
      "peplexity: 4410.02741846713\n",
      "sentence: <start> <start> не голый же дистрибутив продают <end>\n",
      "peplexity: 30260.664356587276\n",
      "sentence: <start> <start> а пятый тред уже был ну я его типо уже вкинул в архив а лол во тупой обосрался с цифрами фух запилил пожалуй ролл ахах оп ты что ебануый х d вот не знаю радоваться или нет <end>\n",
      "peplexity: 25435.601260504867\n",
      "sentence: <start> <start> в то же время известно что этого высокого звания были одновременно удостоены также генералы казанцев и трошев <end>\n",
      "peplexity: 11742.628856728054\n",
      "sentence: <start> <start> его исследуют эксперты <end>\n",
      "peplexity: 27661.97344786237\n",
      "sentence: <start> <start> бюджет будет поставлен на голосование 31 декабря <end>\n",
      "peplexity: 30694.84821400922\n"
     ]
    }
   ],
   "source": [
    "perplexities = []\n",
    "for sentence in test_sentences:\n",
    "    prob = []\n",
    "    \n",
    "    for ngram in ngrammer(sentence, n=3):\n",
    "        word1, word2, word3 = ngram.split()\n",
    "\n",
    "        www = word1 + ' ' + word2\n",
    "        if www in bigrams and ngram in trigrams:\n",
    "            prob.append(np.log(trigrams[ngram]/bigrams[word1 + ' ' + word2]))\n",
    "        else:\n",
    "            prob.append(np.log(0.00001))\n",
    "    \n",
    "    perplexities.append(perplexity(prob))\n",
    "    perplexities.append(perplexity(prob))\n",
    "    print(f'sentence: {\" \".join(sentence)}')\n",
    "    print(f'peplexity: {perplexities[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean perplexity: 29643.698215166678\n"
     ]
    }
   ],
   "source": [
    "print(f'mean perplexity: {np.mean(perplexities)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно увидеть, что перплексия на корпусе из двача и новостей показывает в среднем не очень хорошие результаты. Чтобы повысить качество, возможно нужно добавить ещё больше данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 2* (2 балла). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитайте главу про языковое моделирование в книге Журафски и Мартина - https://web.stanford.edu/~jurafsky/slp3/3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Развернуто (в пределах 1000 знаков) ответьте на вопросы (по-русски):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Что можно делать с проблемой несловарных слов? В семинаре мы просто использовали какое-то маленькое значение вероятности, а какие есть другие способы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистические модели (n-граммная модель является таковой) очень зависят от данных, потому может быть такая ситуация, когда некоторые слова могут не оказаться в тестовой выборке. Такие слова называются неизвестными или выходящие из словаря (out of vocabulary (OOV)). OOV rate называют процент неизвестных слов, которые встретились в тестовой выборке. Чтобы решить такую проблему авторы книги предлагают два пути решения, но главная их идея состоит в присвоении псевдослова \"< UNK >\" неизвестным словам.\n",
    "\n",
    "Первый подход состоит в том, что создаётся фиксированный список слов, в тренировочной выборке слова, которые не попадают в этот список, преобразуются в псевдослово \"< UNK >\" и, наконец, считается вероятность этих слов, как для других.\n",
    "\n",
    "Второй подход заключается в том, чтобы заменять те слова, у которых количество появлений в тренировочном наборе меньше определенного числа, на псевдослово."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Что такое сглаживание (smoothing)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под сглаживанием подразумевается процесс, когда для слов, которые находятся в тренировочном наборе, но контекст для них отсутствует в тестовом, вместо зануления добавляется какая-то часть вероятности, которая берётся у слов c наиболее частотными событиями."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
