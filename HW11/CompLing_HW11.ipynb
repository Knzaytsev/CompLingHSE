{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1dba7c0d",
      "metadata": {
        "id": "1dba7c0d"
      },
      "source": [
        "# Домашнее задание № 11. Машинный перевод"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yj7aripVIsbG",
      "metadata": {
        "id": "Yj7aripVIsbG"
      },
      "source": [
        "## Задание 1 (6 баллов + 2 доп балла).\n",
        "Нужно обучить трансформер на этом же или на другом корпусе (можно взять другую языковую пару с того же сайте) и оценивать его на всей тестовой выборке (а не на 10 примерах как сделал я). \n",
        "\n",
        "Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Подсказка: модель может предсказывать батчами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05d202c4",
      "metadata": {
        "id": "05d202c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81dadcf-2abe-4271-b4a1-5e2e4d0b27f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Installing collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers matplotlib sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade jedi==0.17.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QlKhZd672Xw",
        "outputId": "62bc5c77-132d-4064-8677-141d26e255cf"
      },
      "id": "0QlKhZd672Xw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jedi==0.17.2\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 153 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 163 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 174 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 225 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 266 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 296 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 307 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 317 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 327 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 337 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 348 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 358 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 440 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 450 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 460 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 471 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 481 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 501 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 512 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 522 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 532 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 583 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 593 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 604 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 614 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 634 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 645 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 655 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 665 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 675 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 686 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 696 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 706 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 727 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 737 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 747 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 768 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 778 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 788 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 798 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 808 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 819 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 829 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 839 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 860 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 870 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 880 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 890 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 901 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 911 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 921 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 931 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 942 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 952 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 962 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 972 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 993 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.3 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 7.3 MB/s \n",
            "\u001b[?25hCollecting parso<0.8.0,>=0.7.0\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 70.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: parso, jedi\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.3\n",
            "    Uninstalling parso-0.8.3:\n",
            "      Successfully uninstalled parso-0.8.3\n",
            "  Attempting uninstall: jedi\n",
            "    Found existing installation: jedi 0.18.1\n",
            "    Uninstalling jedi-0.18.1:\n",
            "      Successfully uninstalled jedi-0.18.1\n",
            "Successfully installed jedi-0.17.2 parso-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import normalizers\n",
        "from tokenizers.normalizers import Lowercase\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "from tokenizers import decoders\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "EJWdHnsz77aH"
      },
      "id": "EJWdHnsz77aH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cad0T_9e78Ev",
        "outputId": "30f491f8-103c-4b59-ba8b-7fbaaee460d8"
      },
      "id": "Cad0T_9e78Ev",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-20 12:00:25--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121340806 (116M)\n",
            "Saving to: ‘opus.en-ru-train.ru’\n",
            "\n",
            "opus.en-ru-train.ru 100%[===================>] 115.72M  19.7MB/s    in 6.6s    \n",
            "\n",
            "2022-05-20 12:00:33 (17.5 MB/s) - ‘opus.en-ru-train.ru’ saved [121340806/121340806]\n",
            "\n",
            "--2022-05-20 12:00:33--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67760131 (65M)\n",
            "Saving to: ‘opus.en-ru-train.en’\n",
            "\n",
            "opus.en-ru-train.en 100%[===================>]  64.62M  18.6MB/s    in 4.0s    \n",
            "\n",
            "2022-05-20 12:00:37 (16.1 MB/s) - ‘opus.en-ru-train.en’ saved [67760131/67760131]\n",
            "\n",
            "--2022-05-20 12:00:37--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305669 (299K)\n",
            "Saving to: ‘opus.en-ru-test.ru’\n",
            "\n",
            "opus.en-ru-test.ru  100%[===================>] 298.50K   538KB/s    in 0.6s    \n",
            "\n",
            "2022-05-20 12:00:39 (538 KB/s) - ‘opus.en-ru-test.ru’ saved [305669/305669]\n",
            "\n",
            "--2022-05-20 12:00:39--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173307 (169K)\n",
            "Saving to: ‘opus.en-ru-test.en’\n",
            "\n",
            "opus.en-ru-test.en  100%[===================>] 169.25K   406KB/s    in 0.4s    \n",
            "\n",
            "2022-05-20 12:00:40 (406 KB/s) - ‘opus.en-ru-test.en’ saved [173307/173307]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents = open('opus.en-ru-train.en').read().lower().splitlines()\n",
        "ru_sents = open('opus.en-ru-train.ru').read().lower().splitlines()"
      ],
      "metadata": {
        "id": "kI5oY_ne7924"
      },
      "id": "kI5oY_ne7924",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(WordPiece(), )\n",
        "tokenizer_en.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_en = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en )\n",
        "\n",
        "tokenizer_ru = Tokenizer(WordPiece(), )\n",
        "tokenizer_ru.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_ru = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru )"
      ],
      "metadata": {
        "id": "M1kF1lr48A7Y"
      },
      "id": "M1kF1lr48A7Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.decoder = decoders.WordPiece()\n",
        "tokenizer_ru.decoder = decoders.WordPiece()"
      ],
      "metadata": {
        "id": "CGK7hSub8D3Z"
      },
      "id": "CGK7hSub8D3Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text, tokenizer, target=False):\n",
        "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids + [tokenizer.token_to_id('[SEP]')]\n"
      ],
      "metadata": {
        "id": "jdesgw6V8HEn"
      },
      "id": "jdesgw6V8HEn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_en = [encode(t, tokenizer_en) for t in en_sents]\n",
        "X_ru = [encode(t, tokenizer_ru, target=True) for t in ru_sents]"
      ],
      "metadata": {
        "id": "sXkKxtZA8OGP"
      },
      "id": "sXkKxtZA8OGP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_en, max_len_ru = 20, 22"
      ],
      "metadata": {
        "id": "gU225CoN8Pkg"
      },
      "id": "gU225CoN8Pkg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')"
      ],
      "metadata": {
        "id": "uXqk27bJ8SEP"
      },
      "id": "uXqk27bJ8SEP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_en = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              X_en, maxlen=max_len_en, padding='post', value=tokenizer_en.token_to_id('[PAD]'))\n",
        "\n",
        "X_ru_out = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[1:] for x in X_ru], maxlen=max_len_ru-1, padding='post', \n",
        "              value=tokenizer_en.token_to_id('[PAD]'))\n",
        "\n",
        "X_ru_dec = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[:-1] for x in X_ru], maxlen=max_len_ru-1, \n",
        "              padding='post', value=tokenizer_ru.token_to_id('[PAD]'))"
      ],
      "metadata": {
        "id": "xBZO2naO8Tyw"
      },
      "id": "xBZO2naO8Tyw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_en_train, X_en_valid, X_ru_dec_train, X_ru_dec_valid, X_ru_out_train, X_ru_out_valid = train_test_split(X_en, \n",
        "                                                                                                      X_ru_dec, \n",
        "                                                                                                      X_ru_out, \n",
        "                                                                                                      test_size=0.05)"
      ],
      "metadata": {
        "id": "0SzU1EpL8V3X"
      },
      "id": "0SzU1EpL8V3X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    \"\"\"Calculate the attention weights. \"\"\"\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # add the mask to zero out padding tokens\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k)\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "ZWHlnShS8XiQ"
      },
      "id": "ZWHlnShS8XiQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(\n",
        "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "            'value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # linear layers\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # split heads\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # scaled dot-product attention\n",
        "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # concatenation of heads\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # final linear layer\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "9GKykrq08Z7Q"
      },
      "id": "9GKykrq08Z7Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = tf.cast(tf.math.equal(x, PAD_IDX), tf.float32)\n",
        "    # (batch_size, 1, 1, sequence length)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "HxvBcMMB8b53"
      },
      "id": "HxvBcMMB8b53",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x)\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "id": "vJXGrjRB8c9J"
      },
      "id": "vJXGrjRB8c9J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "id": "xjmB_vxh8eFX"
      },
      "id": "xjmB_vxh8eFX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "6fp10Ugr8fFB"
      },
      "id": "6fp10Ugr8fFB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=\"encoder_layer_{}\".format(i),\n",
        "        )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "eJzE2jS38gNZ"
      },
      "id": "eJzE2jS38gNZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "    attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "UcvAwENM8hFe"
      },
      "id": "UcvAwENM8hFe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name='decoder'):\n",
        "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "jYA0SJeY8iKh"
      },
      "id": "jYA0SJeY8iKh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                max_len,\n",
        "                name=\"transformer\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "    # mask the future tokens for decoder inputs at the 1st attention block\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "    # mask the encoder outputs for the 2nd attention block\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "    enc_outputs = encoder(\n",
        "      vocab_size=vocab_size[0],\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      max_len=max_len[0],\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "    dec_outputs = decoder(\n",
        "      vocab_size=vocab_size[1],\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      max_len=max_len[1],\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size[1], name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "DmH6Cbbc8jXo"
      },
      "id": "DmH6Cbbc8jXo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L  = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none',)\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    loss = L(y_true, y_pred)\n",
        "\n",
        "    mask = tf.cast(tf.not_equal(y_true, PAD_IDX), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "FaA9GGkK8kpv"
      },
      "id": "FaA9GGkK8kpv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "eYanRSGF8mGm"
      },
      "id": "eYanRSGF8mGm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# small model\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "\n",
        "# average model\n",
        "# NUM_LAYERS = 6\n",
        "# D_MODEL = 512\n",
        "# NUM_HEADS = 8\n",
        "# UNITS = 2048\n",
        "# DROPOUT = 0.1\n",
        "\n",
        "\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "with mirrored_strategy.scope():\n",
        "    model = transformer(\n",
        "        vocab_size=(tokenizer_en.get_vocab_size(),tokenizer_ru.get_vocab_size()),\n",
        "        num_layers=NUM_LAYERS,\n",
        "        units=UNITS,\n",
        "        d_model=D_MODEL,\n",
        "        num_heads=NUM_HEADS,\n",
        "        dropout=DROPOUT,\n",
        "        max_len=[max_len_en, max_len_ru])\n",
        "\n",
        "#     learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "    def accuracy(y_true, y_pred):\n",
        "#         y_true = tf.reshape(y_true, shape=(-1, max_len_ru - 1))\n",
        "        return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model_ruen',\n",
        "                                                monitor='val_loss',\n",
        "                                                verbose=1,\n",
        "                                            save_weights_only=True,\n",
        "                                            save_best_only=True,\n",
        "                                            mode='min',\n",
        "                                            save_freq='epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04PLn-Em8nEx",
        "outputId": "2677577a-fc28-441a-d534-f90b4f7e4178"
      },
      "id": "04PLn-Em8nEx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit((X_en_train, X_ru_dec_train), X_ru_out_train, \n",
        "             validation_data=((X_en_valid, X_ru_dec_valid), X_ru_out_valid),\n",
        "             batch_size=200,\n",
        "             epochs=5,\n",
        "             callbacks=[checkpoint]\n",
        "             )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xusHQl0g8oUO",
        "outputId": "e9170027-4d43-4636-dc5f-dc4bacfd821e"
      },
      "id": "xusHQl0g8oUO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "4750/4750 [==============================] - ETA: 0s - loss: 2.3366 - accuracy: 0.2148\n",
            "Epoch 1: val_loss improved from inf to 1.81125, saving model to model_ruen\n",
            "4750/4750 [==============================] - 815s 169ms/step - loss: 2.3366 - accuracy: 0.2148 - val_loss: 1.8113 - val_accuracy: 0.2635\n",
            "Epoch 2/5\n",
            "4750/4750 [==============================] - ETA: 0s - loss: 1.7472 - accuracy: 0.2691\n",
            "Epoch 2: val_loss improved from 1.81125 to 1.64173, saving model to model_ruen\n",
            "4750/4750 [==============================] - 813s 171ms/step - loss: 1.7472 - accuracy: 0.2691 - val_loss: 1.6417 - val_accuracy: 0.2832\n",
            "Epoch 3/5\n",
            "4750/4750 [==============================] - ETA: 0s - loss: 1.6152 - accuracy: 0.2836\n",
            "Epoch 3: val_loss improved from 1.64173 to 1.57840, saving model to model_ruen\n",
            "4750/4750 [==============================] - 814s 171ms/step - loss: 1.6152 - accuracy: 0.2836 - val_loss: 1.5784 - val_accuracy: 0.2904\n",
            "Epoch 4/5\n",
            "4750/4750 [==============================] - ETA: 0s - loss: 1.5480 - accuracy: 0.2913\n",
            "Epoch 4: val_loss improved from 1.57840 to 1.54799, saving model to model_ruen\n",
            "4750/4750 [==============================] - 814s 171ms/step - loss: 1.5480 - accuracy: 0.2913 - val_loss: 1.5480 - val_accuracy: 0.2956\n",
            "Epoch 5/5\n",
            "4750/4750 [==============================] - ETA: 0s - loss: 1.5056 - accuracy: 0.2962\n",
            "Epoch 5: val_loss improved from 1.54799 to 1.52489, saving model to model_ruen\n",
            "4750/4750 [==============================] - 813s 171ms/step - loss: 1.5056 - accuracy: 0.2962 - val_loss: 1.5249 - val_accuracy: 0.2982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe5e326ed10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "tcj3kXc68xHP"
      },
      "id": "tcj3kXc68xHP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents_test = open('opus.en-ru-test.en').read().lower().splitlines()\n",
        "ru_sents_test = open('opus.en-ru-test.ru').read().lower().splitlines()"
      ],
      "metadata": {
        "id": "N0JRpd1h8yJQ"
      },
      "id": "N0JRpd1h8yJQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batches = [en_sents_test[:1000], en_sents_test[1000:]]"
      ],
      "metadata": {
        "id": "HJEBdrl_WYNW"
      },
      "id": "HJEBdrl_WYNW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text_batches):\n",
        "\n",
        "  sentences = []\n",
        "\n",
        "  for batch in text_batches:\n",
        "    # Для каждого \"батча\" формируем вектор входных токенов из N предложений\n",
        "    batches = []\n",
        "    for text in batch:\n",
        "      input_ids = encode(text.lower(), tokenizer_en)\n",
        "\n",
        "      batches.append(input_ids)\n",
        "\n",
        "    input_ids = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "                                        batches, maxlen=max_len_en, padding='post')\n",
        "\n",
        "\n",
        "    # Формируем вектор выходных токенов с размерностью N\n",
        "    output_ids = [[tokenizer_ru.token_to_id('[CLS]') ]]*input_ids.shape[0]\n",
        "\n",
        "    # Предсказываем батчами\n",
        "    preds = model.predict((input_ids, tf.cast(output_ids, tf.int32)), batch_size=256)\n",
        "\n",
        "    # Получаем предсказания по всем токенам\n",
        "    pred = preds.argmax(2)[:, -1]\n",
        "\n",
        "    # Получаем матрицу из предсказаний до тех пор, пока не достигнем максимальной длины предложения на русском\n",
        "    for i in range(max_len_ru - 1):\n",
        "      # Добавляем в матрицу столбец с предсказаниями\n",
        "      output_ids = np.c_[output_ids, pred]\n",
        "      pred = model.predict((input_ids, tf.cast(output_ids, tf.int32)), batch_size=64).argmax(2)[:, -1]\n",
        "\n",
        "    sentences.extend(output_ids)\n",
        "  \n",
        "  return sentences"
      ],
      "metadata": {
        "id": "M2eGoGkjKjv8"
      },
      "id": "M2eGoGkjKjv8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = translate(text_batches)"
      ],
      "metadata": {
        "id": "ECsmFPr_WdIG"
      },
      "id": "ECsmFPr_WdIG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sep_token = tokenizer_ru.token_to_id('[SEP]')"
      ],
      "metadata": {
        "id": "tzuL7NRU18nx"
      },
      "id": "tzuL7NRU18nx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Т.к. мы предсказывали до определённой длины, то нужно сократить предложения до первого встреченного токена [SEP]\n",
        "sentences = [sentence[1:-1 if len(np.where(sentence==sep_token)[0]) == 0 else np.where(sentence==sep_token)[0][0]] for sentence in sentences]\n",
        "sentences = [tokenizer_ru.decode(sentence) for sentence in sentences]"
      ],
      "metadata": {
        "id": "PituEdvU1ocM"
      },
      "id": "PituEdvU1ocM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleus = []\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  reference = tokenizer_ru.encode(sentence).tokens\n",
        "  hypothesis = tokenizer_ru.encode(ru_sents_test[i]).tokens\n",
        "\n",
        "bleus.append(nltk.translate.bleu_score.sentence_bleu([reference], hypothesis,  ))"
      ],
      "metadata": {
        "id": "jNncKkEh28V6"
      },
      "id": "jNncKkEh28V6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(sum(bleus)/len(bleus))*100"
      ],
      "metadata": {
        "id": "kZmF4Czk2895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba31be4-6782-4515-c4f9-ee89a85c7ef2"
      },
      "id": "kZmF4Czk2895",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.806687382400554"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как можно видеть, качество модели не самое хорошее. Нужно увеличить количество эпох, но т.к. модель обучается долго, то я остановился только на 5.\n",
        "\n",
        "Скорость предсказания увеличилась во много раз, однако вместе с этим же увеличилось и количество затрачиваемой оперативной памяти графического процессора. В теории это можно сократить тем, что после каждого предсказания у выходных токенов смотреть те списки, которые оканчиваются на токен [SEP] и вытаскивать их в общий список с предложениями, не забывая о входных токенах для соблюдения одинаковой размерности."
      ],
      "metadata": {
        "id": "FdAEtaztqCdE"
      },
      "id": "FdAEtaztqCdE"
    },
    {
      "cell_type": "markdown",
      "id": "b5aa93d6",
      "metadata": {
        "id": "b5aa93d6"
      },
      "source": [
        "\n",
        "## Задание 2 (2 балла).\n",
        "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/10.pdf \n",
        "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как его применить к паре en-ru на данных из семинара. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Техника заключается в том, что имея в наличии небольшой параллельный корпус (например, навахо-английский) можно обучить модель переводить предложения с английского на навахский и таким образом получить больше текста на двух языках. Техника позволяет получить синтетический параллельный корпус в тех ситуациях, когда есть достаточно большой корпус одного языка, но при этом в наличии маленький параллельный корпус.\n",
        "Для пары en-ru технику можно применить следующим образом:\n",
        "1. Обучаем MT-модель переводить с русского на английский по существующему параллельному корпусу.\n",
        "2. По предложениям из русского генерируем предложения на английском, применяя различные параметры (beam search, Monte Carlo search, семплирование и т.д.).\n",
        "3. Добавляем сгенерированные предложения в параллельный корпус.\n",
        "4. Тренируем MT-модель на перевод с английского на русский."
      ],
      "metadata": {
        "id": "H73Oz_uI0zjB"
      },
      "id": "H73Oz_uI0zjB"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "CompLing_HW11",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}