{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание  № 5. Матричные разложения/Тематическое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание № 1 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте матричные разложения с 5 классификаторами - SGDClassifier, KNeighborsClassifier, MultinomialNB, RandomForest, ExtraTreesClassifier (про него подробнее почитайте в документации, он похож на RF). Используйте и NMF и SVD. Сравните результаты на кросс-валидации и выберите лучшее сочетание.\n",
    "\n",
    "В итоге у вас должно получиться, как минимум 10 моделей (два разложения на каждый классификатор). Используйте 1 и те же параметры кросс-валидации. Параметры векторизации, параметры K в матричных разложениях, параметры классификаторов могут быть разными между экспериментами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можете взять поменьше данных, если все будет обучаться слишком долго (не ставьте параметр K слишком большим в NMF, иначе точно будет слишком долго)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from gensim) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA, LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "morph = MorphAnalyzer()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/avito_category_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    normalized_text = [morph.parse(word)[0].normal_form for word in normalized_text]\n",
    "    return ' '.join(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description_norm'] = data['description'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = 5\n",
    "max_df = 0.1\n",
    "nmf_size = 200\n",
    "tokenizer = lambda x: x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'SGD_NMF' : Pipeline([\n",
    "    ('bow', TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,4), min_df=min_df, max_df=max_df)),\n",
    "    ('nmf', NMF(nmf_size)),\n",
    "    ('clf', SGDClassifier(max_iter=1000, tol=1e-3))]),\n",
    "    'KNeighbors_NMF' : Pipeline([\n",
    "    ('bow', TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,4), min_df=min_df, max_df=max_df)),\n",
    "    ('nmf', NMF(nmf_size)),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=5))]),\n",
    "    'RandomForest_NMF' : Pipeline([\n",
    "    ('bow', TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,4), min_df=min_df, max_df=max_df)),\n",
    "    ('nmf', NMF(nmf_size)),\n",
    "    ('clf', RandomForestClassifier(max_depth=10, random_state=0))]),\n",
    "    'ExtraTree_NMF' : Pipeline([\n",
    "    ('bow', TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,4), min_df=min_df, max_df=max_df)),\n",
    "    ('nmf', NMF(nmf_size)),\n",
    "    ('clf', ExtraTreesClassifier(n_estimators=300, random_state=0))]),\n",
    "    \n",
    "    'SGD_SVD' : Pipeline([\n",
    "    ('bow', TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,3), min_df=min_df, max_df=max_df)),\n",
    "    ('svd', TruncatedSVD(500)),\n",
    "    ('clf', SGDClassifier(max_iter=100, tol=1e-3))]),\n",
    "    'KNeighbors_SVD' : Pipeline([\n",
    "    ('bow', TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,3), min_df=min_df, max_df=max_df)),\n",
    "    ('svd', TruncatedSVD(500)),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=5))]),\n",
    "    'RandomForest_SVD' : Pipeline([\n",
    "    ('bow', TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,3), min_df=min_df, max_df=max_df)),\n",
    "    ('svd', TruncatedSVD(500)),\n",
    "    ('clf', RandomForestClassifier(max_depth=10, random_state=0))]),\n",
    "    'ExtraTree_SVD' : Pipeline([\n",
    "    ('bow', TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,3), min_df=min_df, max_df=max_df)),\n",
    "    ('svd', TruncatedSVD(500)),\n",
    "    ('clf', ExtraTreesClassifier(n_estimators=300, random_state=0))]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_table(X, y, pipeline, N=6):\n",
    "    # зафиксируем порядок классов\n",
    "    labels = list(set(y))\n",
    "    \n",
    "    # метрики отдельных фолдов будет хранить в табличке\n",
    "    fold_metrics = pd.DataFrame(index=labels)\n",
    "    # дополнительно также соберем таблицу ошибок\n",
    "    errors = np.zeros((len(labels), len(labels)))\n",
    "    \n",
    "    # создаем стратегию кросс-валидации\n",
    "    # shuffle=True (перемешивание) - часто критично важно указать\n",
    "    # т.к. данные могут быть упорядочены и модель на этом обучится\n",
    "    kfold = StratifiedKFold(n_splits=N, shuffle=True, )\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        # fit-predict как и раньше, но сразу пайплайном\n",
    "        pipeline.fit(X[train_index], y[train_index])\n",
    "        preds = pipeline.predict(X[test_index])\n",
    "        \n",
    "        # записываем метрику и индекс фолда\n",
    "        fold_metrics[f'precision_{i}'] = precision_score(y[test_index], preds, labels=labels, average=None)\n",
    "        fold_metrics[f'recall_{i}'] = recall_score(y[test_index], preds, labels=labels, average=None)\n",
    "        fold_metrics[f'f1_{i}'] = f1_score(y[test_index], preds, labels=labels, average=None)\n",
    "        errors += confusion_matrix(y[test_index], preds, labels=labels, normalize='true')\n",
    "    \n",
    "    # таблица для усредненных значений\n",
    "    # тут мы берем колонки со значениями и усредняем их\n",
    "    # часто также все метрики сразу суммируют и в конце просто делят на количество фолдов\n",
    "    # но мы тут помимо среднего также хотим посмотреть на стандартное отклонение\n",
    "    # чтобы понять как сильно варьируются оценки моделей\n",
    "    result = pd.DataFrame(index=labels)\n",
    "    result['precision'] = fold_metrics[[f'precision_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['precision_std'] = fold_metrics[[f'precision_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    result['recall'] = fold_metrics[[f'recall_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['recall_std'] = fold_metrics[[f'recall_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    result['f1'] = fold_metrics[[f'f1_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['f1_std'] = fold_metrics[[f'f1_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    # добавим одну колонку со средним по всем классам\n",
    "    result.loc['mean'] = result.mean().round(2)\n",
    "    # проценты ошибок просто усредняем\n",
    "    errors /= N\n",
    "    \n",
    "    return result, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD_NMF\n",
      "KNeighbors_NMF\n",
      "RandomForest_NMF\n",
      "ExtraTree_NMF\n",
      "SGD_SVD\n",
      "KNeighbors_SVD\n",
      "RandomForest_SVD\n",
      "ExtraTree_SVD\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = {}\n",
    "\n",
    "for algo, pipeline in pipelines.items():\n",
    "    print(algo)\n",
    "    metrics, errors = eval_table(data['description_norm'], data['category_name'], pipeline)\n",
    "    metrics_dict[algo] = (metrics, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(difference):\n",
    "    positives = sum(x > 0 for x in difference)\n",
    "    negatives = sum(x < 0 for x in difference)\n",
    "    return int((positives - negatives) >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_metric(metrics):\n",
    "    metrics_idx = {i: name for i, name in enumerate(metrics.keys())}\n",
    "    \n",
    "    curr_metric = 0\n",
    "    for i in range(1, len(metrics_idx)):\n",
    "        difference = metrics[metrics_idx[curr_metric]][0].loc['mean'] - metrics[metrics_idx[curr_metric]][0].loc['mean']\n",
    "        chosen_metric = compare_metrics(difference)\n",
    "        curr_metric = curr_metric if chosen_metric == 0 else i\n",
    "    return metrics_idx[curr_metric], metrics[metrics_idx[curr_metric]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best_metric(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ExtraTree_SVD'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Предложение услуг</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Мебель и интерьер</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Детская одежда и обувь</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Квартиры</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Одежда, обувь, аксессуары</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Товары для детей и игрушки</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Телефоны</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Автомобили</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ремонт и строительство</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Бытовая техника</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            precision  precision_std  recall  recall_std  \\\n",
       "Предложение услуг                0.76           0.03    0.69        0.05   \n",
       "Мебель и интерьер                0.79           0.07    0.35        0.07   \n",
       "Детская одежда и обувь           0.62           0.02    0.75        0.02   \n",
       "Квартиры                         0.96           0.02    0.95        0.02   \n",
       "Одежда, обувь, аксессуары        0.54           0.02    0.78        0.04   \n",
       "Товары для детей и игрушки       0.83           0.06    0.43        0.02   \n",
       "Телефоны                         0.86           0.05    0.63        0.03   \n",
       "Автомобили                       0.87           0.03    0.84        0.04   \n",
       "Ремонт и строительство           0.68           0.07    0.27        0.04   \n",
       "Бытовая техника                  0.63           0.12    0.18        0.05   \n",
       "mean                             0.75           0.05    0.59        0.04   \n",
       "\n",
       "                              f1  f1_std  \n",
       "Предложение услуг           0.72    0.03  \n",
       "Мебель и интерьер           0.48    0.07  \n",
       "Детская одежда и обувь      0.68    0.01  \n",
       "Квартиры                    0.96    0.01  \n",
       "Одежда, обувь, аксессуары   0.64    0.03  \n",
       "Товары для детей и игрушки  0.57    0.03  \n",
       "Телефоны                    0.73    0.03  \n",
       "Автомобили                  0.86    0.03  \n",
       "Ремонт и строительство      0.38    0.05  \n",
       "Бытовая техника             0.28    0.07  \n",
       "mean                        0.63    0.04  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате обучения всех моделей наилучшим способом по средним метрикам показало себя сочетание разложения SVD и модели ExtraTreesClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание № 2 (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Gensim тоже можно добавить нграммы и tfidf. Постройте 1 модель без них (как в семинаре) и еще 3 модели (1 с нграммами, 1 с tfidf и 1 с нграммами и с tfidf). Сранивте качество с помощью метрик (перплексия, когерентность) и на глаз. Определите лучшую модель. Для каждой модели выберите 1 самую красивую на ваш взгляд тему.\n",
    "\n",
    "Используйте данные википедии из семинара. Можете взять поменьше данных, если все обучается долго.\n",
    "\n",
    "Важное требование - получившиеся модели не должны быть совсем плохими. Если хороших тем не получается, попробуйте настроить гиперпараметры, отфильтровать словарь по-другому. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(texts, no_above=0.1, no_below=10):\n",
    "    dictinary = gensim.corpora.Dictionary(texts)\n",
    "    \n",
    "    dictinary.filter_extremes(no_above=no_above, no_below=no_below)\n",
    "    dictinary.compactify()\n",
    "    \n",
    "    return dictinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(dictionary, texts):\n",
    "    return [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_lda(texts, corpus=None, dictinary=None, no_above=0.2, no_below=20, alpha='asymmetric', passes=5):\n",
    "    if dictinary is None:\n",
    "        dictinary = get_dictionary(texts, no_above, no_below)\n",
    "    \n",
    "    if corpus is None:\n",
    "        corpus = get_corpus(dictinary, texts)\n",
    "    \n",
    "    lda = gensim.models.LdaMulticore(corpus, \n",
    "                                 100, # колиество тем\n",
    "                                 alpha=alpha,\n",
    "                                 id2word=dictinary, \n",
    "                                 passes=passes)\n",
    "    \n",
    "    show_metrics(corpus, texts, dictinary, lda)\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(corpus, texts, dictinary, lda):\n",
    "    print(f'Perplexity: {np.exp2(-lda.log_perplexity(corpus))}')\n",
    "    \n",
    "    topics = []\n",
    "    for topic_id, topic in lda.show_topics(num_topics=100, formatted=False):\n",
    "        topic = [word for word, _ in topic]\n",
    "        topics.append(topic)\n",
    "        \n",
    "    coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=texts, \n",
    "                                                   dictionary=dictinary, coherence='c_v')\n",
    "    \n",
    "    print(f'Coherence: {coherence_model_lda.get_coherence()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_all_models(texts):\n",
    "    print('Clear model')\n",
    "    splitted_texts = [text.split() for text in texts]\n",
    "    lda = pipeline_lda(splitted_texts)\n",
    "    pprint(lda.print_topics())\n",
    "    \n",
    "    print('\\nN-gram model')\n",
    "    texts_ngram = splitted_texts\n",
    "    ph = gensim.models.Phrases(texts_ngram, scoring='npmi', threshold=0.3) # threshold можно подбирать\n",
    "    p = gensim.models.phrases.Phraser(ph)\n",
    "    ngrammed_texts = p[texts_ngram] \n",
    "    lda = pipeline_lda(ngrammed_texts)\n",
    "    pprint(lda.print_topics())\n",
    "    \n",
    "    print('\\nTfIdf model')\n",
    "    dictinary = get_dictionary(splitted_texts)\n",
    "    corpus = get_corpus(dictinary, splitted_texts)\n",
    "    tfidf = gensim.models.TfidfModel(corpus, id2word=dictinary, )\n",
    "    corpus = tfidf[corpus]\n",
    "    lda = pipeline_lda(splitted_texts, corpus, dictinary)\n",
    "    pprint(lda.print_topics())\n",
    "    \n",
    "    print('\\nN-gram and Tfidf model')\n",
    "    dictinary = get_dictionary(ngrammed_texts)\n",
    "    corpus = get_corpus(dictinary, ngrammed_texts)\n",
    "    tfidf = gensim.models.TfidfModel(corpus, id2word=dictinary, )\n",
    "    corpus = tfidf[corpus]\n",
    "    lda = pipeline_lda(ngrammed_texts, corpus, dictinary)\n",
    "    pprint(lda.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = open('data\\wiki_data.txt', encoding='utf-8').read().splitlines()[:5000]\n",
    "texts = ([normalize(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clear model\n",
      "Perplexity: 309.6407181282191\n",
      "Coherence: 0.5178923636135297\n",
      "[(99,\n",
      "  '0.041*\"картина\" + 0.020*\"мария\" + 0.019*\"портрет\" + 0.015*\"изобразить\" + '\n",
      "  '0.010*\"г\" + 0.010*\"её\" + 0.010*\"художник\" + 0.009*\"у\" + 0.008*\"пятно\" + '\n",
      "  '0.007*\"галерея\"'),\n",
      " (97,\n",
      "  '0.012*\"или\" + 0.009*\"система\" + 0.008*\"мочь\" + 0.007*\"так\" + 0.007*\"иметь\" '\n",
      "  '+ 0.006*\"использовать\" + 0.005*\"устройство\" + 0.005*\"другой\" + '\n",
      "  '0.005*\"можно\" + 0.004*\"такой\"'),\n",
      " (98,\n",
      "  '0.039*\"марка\" + 0.030*\"вино\" + 0.022*\"почтовый\" + 0.013*\"остров\" + '\n",
      "  '0.013*\"город\" + 0.010*\"выпуск\" + 0.006*\"под\" + 0.005*\"почта\" + 0.005*\"марк\" '\n",
      "  '+ 0.005*\"новый\"'),\n",
      " (96,\n",
      "  '0.014*\"f\" + 0.012*\"у\" + 0.008*\"бокс\" + 0.007*\"век\" + 0.007*\"l\" + '\n",
      "  '0.007*\"залив\" + 0.006*\"россия\" + 0.006*\"она\" + 0.005*\"здание\" + '\n",
      "  '0.005*\"город\"'),\n",
      " (95,\n",
      "  '0.017*\"вид\" + 0.012*\"яйцо\" + 0.010*\"личинка\" + 0.009*\"северный\" + '\n",
      "  '0.009*\"звезда\" + 0.008*\"питаться\" + 0.007*\"тело\" + 0.007*\"площадь\" + '\n",
      "  '0.007*\"самка\" + 0.006*\"встречаться\"'),\n",
      " (94,\n",
      "  '0.011*\"религиозный\" + 0.008*\"передача\" + 0.008*\"закон\" + 0.008*\"территория\" '\n",
      "  '+ 0.007*\"церковь\" + 0.007*\"имущество\" + 0.007*\"культура\" + 0.006*\"россия\" + '\n",
      "  '0.005*\"российский\" + 0.005*\"издательство\"'),\n",
      " (93,\n",
      "  '0.023*\"или\" + 0.023*\"длина\" + 0.022*\"смотреть\" + 0.018*\"вид\" + 0.015*\"мм\" + '\n",
      "  '0.010*\"лист\" + 0.009*\"м\" + 0.008*\"высота\" + 0.008*\"ширина\" + '\n",
      "  '0.008*\"диаметр\"'),\n",
      " (90,\n",
      "  '0.044*\"князь\" + 0.024*\"иван\" + 0.018*\"василий\" + 0.017*\"парк\" + '\n",
      "  '0.016*\"великий\" + 0.016*\"василиевич\" + 0.013*\"иванович\" + '\n",
      "  '0.009*\"михаилович\" + 0.009*\"княжество\" + 0.008*\"воевода\"'),\n",
      " (92,\n",
      "  '0.018*\"растение\" + 0.016*\"или\" + 0.010*\"земля\" + 0.009*\"тыс\" + 0.007*\"вода\" '\n",
      "  '+ 0.006*\"часть\" + 0.005*\"страна\" + 0.005*\"вид\" + 0.005*\"век\" + '\n",
      "  '0.004*\"более\"'),\n",
      " (91,\n",
      "  '0.020*\"де\" + 0.009*\"оскар\" + 0.007*\"над\" + 0.006*\"вода\" + 0.006*\"врач\" + '\n",
      "  '0.006*\"ла\" + 0.006*\"москва\" + 0.005*\"н\" + 0.005*\"г\" + 0.005*\"дом\"'),\n",
      " (9,\n",
      "  '0.017*\"брак\" + 0.013*\"право\" + 0.011*\"животное\" + 0.007*\"мочь\" + 0.006*\"у\" '\n",
      "  '+ 0.006*\"ребёнок\" + 0.006*\"россия\" + 0.005*\"однако\" + 0.005*\"семья\" + '\n",
      "  '0.005*\"такой\"'),\n",
      " (8,\n",
      "  '0.009*\"город\" + 0.007*\"горный\" + 0.006*\"уровень\" + 0.005*\"часть\" + '\n",
      "  '0.005*\"тропический\" + 0.005*\"или\" + 0.005*\"сезон\" + 0.004*\"журнал\" + '\n",
      "  '0.004*\"уезд\" + 0.004*\"новый\"'),\n",
      " (7,\n",
      "  '0.010*\"песня\" + 0.010*\"вид\" + 0.008*\"часть\" + 0.007*\"группа\" + 0.006*\"штат\" '\n",
      "  '+ 0.006*\"индия\" + 0.005*\"или\" + 0.005*\"м\" + 0.005*\"гора\" + 0.005*\"уровень\"'),\n",
      " (6,\n",
      "  '0.008*\"член\" + 0.007*\"россия\" + 0.007*\"работать\" + 0.007*\"университет\" + '\n",
      "  '0.006*\"г\" + 0.006*\"работа\" + 0.006*\"наука\" + 0.006*\"москва\" + '\n",
      "  '0.006*\"государственный\" + 0.005*\"институт\"'),\n",
      " (5,\n",
      "  '0.013*\"турнир\" + 0.007*\"смочь\" + 0.007*\"раунд\" + 0.007*\"место\" + '\n",
      "  '0.006*\"сектор\" + 0.006*\"мир\" + 0.006*\"второй\" + 0.005*\"финал\" + '\n",
      "  '0.005*\"часть\" + 0.005*\"открытый\"'),\n",
      " (4,\n",
      "  '0.077*\"игра\" + 0.077*\"олимпийский\" + 0.050*\"летний\" + 0.040*\"участие\" + '\n",
      "  '0.038*\"принимать\" + 0.035*\"медаль\" + 0.033*\"завоевать\" + 0.031*\"история\" + '\n",
      "  '0.031*\"раз\" + 0.024*\"ни\"'),\n",
      " (3,\n",
      "  '0.031*\"клуб\" + 0.024*\"матч\" + 0.013*\"команда\" + 0.011*\"состав\" + '\n",
      "  '0.010*\"игра\" + 0.009*\"перейти\" + 0.009*\"чемпионат\" + 0.009*\"игрок\" + '\n",
      "  '0.008*\"забить\" + 0.008*\"гол\"'),\n",
      " (2,\n",
      "  '0.044*\"хутор\" + 0.023*\"река\" + 0.021*\"поселение\" + 0.019*\"ростовский\" + '\n",
      "  '0.016*\"сельский\" + 0.011*\"расположить\" + 0.010*\"входить\" + 0.010*\"км\" + '\n",
      "  '0.009*\"территория\" + 0.008*\"памятник\"'),\n",
      " (1,\n",
      "  '0.016*\"ван\" + 0.009*\"римский\" + 0.008*\"провинция\" + 0.008*\"китай\" + '\n",
      "  '0.007*\"родиться\" + 0.007*\"вместе\" + 0.006*\"город\" + 0.006*\"день\" + '\n",
      "  '0.006*\"июль\" + 0.005*\"арестовать\"'),\n",
      " (0,\n",
      "  '0.013*\"вид\" + 0.009*\"она\" + 0.009*\"мочь\" + 0.008*\"другой\" + 0.008*\"или\" + '\n",
      "  '0.008*\"у\" + 0.007*\"иметь\" + 0.007*\"так\" + 0.007*\"то\" + 0.006*\"такой\"')]\n",
      "\n",
      "N-gram model\n",
      "Perplexity: 454.1241278089564\n",
      "Coherence: 0.4710203463653977\n",
      "[(99,\n",
      "  '0.012*\"горный\" + 0.012*\"царь\" + 0.012*\"битва\" + 0.011*\"институт\" + '\n",
      "  '0.009*\"журнал\" + 0.008*\"война\" + 0.006*\"книга\" + 0.006*\"но\" + 0.005*\"о\" + '\n",
      "  '0.005*\"что\"'),\n",
      " (98,\n",
      "  '0.018*\"или\" + 0.014*\"при\" + 0.009*\"остров\" + 0.009*\"автомобиль\" + '\n",
      "  '0.009*\"что\" + 0.007*\"иметь\" + 0.006*\"являться\" + 0.006*\"колесо\" + '\n",
      "  '0.005*\"её\" + 0.005*\"например\"'),\n",
      " (97,\n",
      "  '0.014*\"фабрика\" + 0.014*\"день\" + 0.010*\"поляк\" + 0.007*\"весь\" + '\n",
      "  '0.006*\"белоруссия\" + 0.005*\"игра_2002\" + 0.005*\"у\" + 0.005*\"город\" + '\n",
      "  '0.005*\"праздник\" + 0.004*\"часть\"'),\n",
      " (96,\n",
      "  '0.032*\"город\" + 0.023*\"здание\" + 0.020*\"проект\" + 0.018*\"строительство\" + '\n",
      "  '0.013*\"музей\" + 0.013*\"церковь\" + 0.012*\"архитектор\" + 0.009*\"работа\" + '\n",
      "  '0.007*\"городской\" + 0.007*\"сооружение\"'),\n",
      " (95,\n",
      "  '0.053*\"село\" + 0.032*\"район\" + 0.017*\"—_село\" + 0.013*\"расположить\" + '\n",
      "  '0.010*\"группа\" + 0.010*\"река\" + 0.008*\"человек\" + 0.007*\"сельсовет\" + '\n",
      "  '0.007*\"город\" + 0.007*\"входить_в\"'),\n",
      " (94,\n",
      "  '0.018*\"дом\" + 0.009*\"город\" + 0.008*\"новый\" + 0.006*\"улица\" + '\n",
      "  '0.006*\"больница\" + 0.005*\"работать\" + 0.005*\"центр\" + 0.005*\"ребёнок\" + '\n",
      "  '0.004*\"3\" + 0.004*\"весь\"'),\n",
      " (92,\n",
      "  '0.019*\"животное\" + 0.016*\"вид\" + 0.013*\"или\" + 0.012*\"тело\" + '\n",
      "  '0.010*\"семейство\" + 0.009*\"птица\" + 0.008*\"другой\" + 0.007*\"самка\" + '\n",
      "  '0.007*\"смотреть\" + 0.007*\"культура\"'),\n",
      " (93,\n",
      "  '0.009*\"партия\" + 0.007*\"о\" + 0.007*\"король\" + 0.006*\"выборы\" + 0.006*\"что\" '\n",
      "  '+ 0.006*\"или\" + 0.006*\"другой\" + 0.005*\"новый\" + 0.005*\"тайвань\" + '\n",
      "  '0.005*\"термин\"'),\n",
      " (91,\n",
      "  '0.040*\"хутор\" + 0.016*\"поселение\" + 0.014*\"сельский_поселение\" + '\n",
      "  '0.014*\"село\" + 0.013*\"расположить\" + 0.012*\"–\" + 0.012*\"человек\" + '\n",
      "  '0.011*\"деревня\" + 0.010*\"центр\" + 0.009*\"ростовский_область\"'),\n",
      " (90,\n",
      "  '0.010*\"илья\" + 0.010*\"сопротивление\" + 0.009*\"календарь\" + 0.007*\"место\" + '\n",
      "  '0.007*\"весь\" + 0.005*\"день\" + 0.005*\"потеря\" + 0.005*\"проект\" + '\n",
      "  '0.005*\"один\" + 0.005*\"неделя\"'),\n",
      " (9,\n",
      "  '0.013*\"4\" + 0.011*\"спортсмен\" + 0.010*\"3\" + 0.009*\"результат\" + '\n",
      "  '0.009*\"место\" + 0.007*\"2\" + 0.007*\"6\" + 0.006*\"олимпиада\" + '\n",
      "  '0.006*\"участие_в\" + 0.006*\"олимпийский_игра\"'),\n",
      " (8,\n",
      "  '0.019*\"cryptocephalus\" + 0.013*\"из_подсемейство\" + 0.013*\"департамент\" + '\n",
      "  '0.011*\"вид\" + 0.010*\"аргентина\" + 0.009*\"человек\" + 0.009*\"часовня\" + '\n",
      "  '0.008*\"что\" + 0.008*\"список\" + 0.008*\"территория\"'),\n",
      " (7,\n",
      "  '0.010*\"корабль\" + 0.008*\"система\" + 0.008*\"компания\" + 0.006*\"новый\" + '\n",
      "  '0.005*\"группа\" + 0.005*\"версия\" + 0.004*\"президент\" + 0.004*\"американский\" '\n",
      "  '+ 0.004*\"федеральный\" + 0.004*\"партия\"'),\n",
      " (6,\n",
      "  '0.011*\"новый\" + 0.010*\"завоевать_ни\" + 0.010*\"один_медаль\" + '\n",
      "  '0.010*\"указ_пвс\" + 0.008*\"переименовать_в\" + 0.007*\"дворец\" + '\n",
      "  '0.007*\"являться\" + 0.006*\"1946_год\" + 0.006*\"но_не\" + 0.006*\"палата\"'),\n",
      " (5,\n",
      "  '0.021*\"№\" + 0.009*\"улица\" + 0.007*\"убийца\" + 0.007*\"газета\" + 0.007*\"город\" '\n",
      "  '+ 0.004*\"работа\" + 0.004*\"ворота\" + 0.004*\"после\" + 0.004*\"начало\" + '\n",
      "  '0.004*\"день\"'),\n",
      " (4,\n",
      "  '0.006*\"что\" + 0.006*\"но\" + 0.005*\"о\" + 0.005*\"новый\" + 0.005*\"весь\" + '\n",
      "  '0.004*\"однако\" + 0.004*\"монастырь\" + 0.004*\"город\" + 0.004*\"после\" + '\n",
      "  '0.004*\"один_из\"'),\n",
      " (3,\n",
      "  '0.014*\"ссср\" + 0.011*\"москва\" + 0.008*\"работать\" + 0.008*\"команда\" + '\n",
      "  '0.008*\"россия\" + 0.007*\"сергей\" + 0.006*\"история\" + 0.006*\"родиться\" + '\n",
      "  '0.005*\"—_советский\" + 0.005*\"российский\"'),\n",
      " (2,\n",
      "  '0.018*\"канада\" + 0.018*\"компания\" + 0.009*\"город\" + 0.008*\"канадский\" + '\n",
      "  '0.006*\"являться\" + 0.006*\"штат\" + 0.006*\"или\" + 0.005*\"россия\" + '\n",
      "  '0.005*\"сша\" + 0.005*\"весь\"'),\n",
      " (1,\n",
      "  '0.025*\"песня\" + 0.023*\"альбом\" + 0.023*\"группа\" + 0.015*\"музыкальный\" + '\n",
      "  '0.015*\"музыка\" + 0.010*\"музыкант\" + 0.010*\"the\" + 0.009*\"композитор\" + '\n",
      "  '0.007*\"концерт\" + 0.007*\"оркестр\"'),\n",
      " (0,\n",
      "  '0.006*\"программа\" + 0.006*\"общество\" + 0.005*\"человек\" + 0.005*\"она\" + '\n",
      "  '0.004*\"два\" + 0.004*\"команда\" + 0.004*\"место\" + 0.004*\"город\" + 0.004*\"сша\" '\n",
      "  '+ 0.004*\"журнал\"')]\n",
      "\n",
      "TfIdf model\n",
      "Perplexity: 20832.883129146805\n",
      "Coherence: 0.376413131786299\n",
      "[(99,\n",
      "  '0.001*\"екатеринбург\" + 0.001*\"книга\" + 0.000*\"мост\" + 0.000*\"детский\" + '\n",
      "  '0.000*\"красноярск\" + 0.000*\"пьеса\" + 0.000*\"школа\" + 0.000*\"красноярский\" + '\n",
      "  '0.000*\"магистраль\" + 0.000*\"край\"'),\n",
      " (98,\n",
      "  '0.084*\"овручский\" + 0.001*\"нацист\" + 0.000*\"on\" + 0.000*\"ирландский\" + '\n",
      "  '0.000*\"ирландия\" + 0.000*\"проект\" + 0.000*\"школа\" + 0.000*\"расстрел\" + '\n",
      "  '0.000*\"церковь\" + 0.000*\"записать\"'),\n",
      " (96,\n",
      "  '0.069*\"полюс\" + 0.001*\"собака\" + 0.001*\"линь\" + 0.001*\"переезжать\" + '\n",
      "  '0.001*\"экспедиция\" + 0.001*\"китайский\" + 0.000*\"университет\" + '\n",
      "  '0.000*\"скотт\" + 0.000*\"философия\" + 0.000*\"полярный\"'),\n",
      " (97,\n",
      "  '0.012*\"туман\" + 0.010*\"пионерский\" + 0.004*\"корабль\" + 0.002*\"комикс\" + '\n",
      "  '0.001*\"епархия\" + 0.001*\"руб\" + 0.001*\"чёрный\" + 0.001*\"ричард\" + '\n",
      "  '0.001*\"серия\" + 0.001*\"влксм\"'),\n",
      " (95,\n",
      "  '0.000*\"продажа\" + 0.000*\"противоречить\" + 0.000*\"пребывание\" + '\n",
      "  '0.000*\"признанный\" + 0.000*\"принудительный\" + 0.000*\"прогресс\" + '\n",
      "  '0.000*\"поправка\" + 0.000*\"противоречие\" + 0.000*\"смертный\" + '\n",
      "  '0.000*\"рассмотрение\"'),\n",
      " (94,\n",
      "  '0.001*\"альбом\" + 0.001*\"the\" + 0.001*\"полигон\" + 0.001*\"hell\" + '\n",
      "  '0.000*\"италия\" + 0.000*\"итальянский\" + 0.000*\"песня\" + 0.000*\"of\" + '\n",
      "  '0.000*\"поздний\" + 0.000*\"live\"'),\n",
      " (93,\n",
      "  '0.000*\"продажа\" + 0.000*\"противоречить\" + 0.000*\"пребывание\" + '\n",
      "  '0.000*\"признанный\" + 0.000*\"принудительный\" + 0.000*\"прогресс\" + '\n",
      "  '0.000*\"поправка\" + 0.000*\"противоречие\" + 0.000*\"смертный\" + '\n",
      "  '0.000*\"рассмотрение\"'),\n",
      " (92,\n",
      "  '0.020*\"соль\" + 0.004*\"реабилитация\" + 0.003*\"лечебный\" + '\n",
      "  '0.002*\"восстановительный\" + 0.002*\"пациент\" + 0.001*\"больница\" + '\n",
      "  '0.001*\"лечение\" + 0.000*\"кабинет\" + 0.000*\"медицинский\" + '\n",
      "  '0.000*\"заболевание\"'),\n",
      " (91,\n",
      "  '0.001*\"атаман\" + 0.001*\"войско\" + 0.001*\"казак\" + 0.000*\"казачий\" + '\n",
      "  '0.000*\"…\" + 0.000*\"армия\" + 0.000*\"черноморский\" + 0.000*\"императрица\" + '\n",
      "  '0.000*\"белый\" + 0.000*\"кубань\"'),\n",
      " (90,\n",
      "  '0.001*\"абхазия\" + 0.001*\"снк\" + 0.001*\"улица\" + 0.001*\"сср\" + '\n",
      "  '0.001*\"батальон\" + 0.001*\"роль\" + 0.001*\"цик\" + 0.001*\"республика\" + '\n",
      "  '0.001*\"полка\" + 0.001*\"стрелковый\"'),\n",
      " (9,\n",
      "  '0.019*\"ален\" + 0.012*\"дмитрий\" + 0.006*\"географический\" + 0.006*\"джейн\" + '\n",
      "  '0.005*\"юриевич\" + 0.003*\"охранник\" + 0.002*\"княгиня\" + 0.002*\"кевин\" + '\n",
      "  '0.002*\"юар\" + 0.002*\"свадьба\"'),\n",
      " (8,\n",
      "  '0.079*\"люксембург\" + 0.018*\"квинта\" + 0.007*\"монтаж\" + 0.006*\"консул\" + '\n",
      "  '0.005*\"слон\" + 0.004*\"римлянин\" + 0.004*\"пароход\" + 0.004*\"файл\" + '\n",
      "  '0.003*\"стокгольм\" + 0.003*\"копьё\"'),\n",
      " (7,\n",
      "  '0.010*\"брейк\" + 0.010*\"филиппина\" + 0.008*\"макс\" + 0.007*\"полномочный\" + '\n",
      "  '0.007*\"югославия\" + 0.005*\"битва\" + 0.005*\"сербский\" + 0.004*\"форт\" + '\n",
      "  '0.004*\"чрезвычайный\" + 0.003*\"джонсон\"'),\n",
      " (6,\n",
      "  '0.026*\"белок\" + 0.018*\"термин\" + 0.012*\"шпицберген\" + 0.008*\"контекст\" + '\n",
      "  '0.007*\"клетка\" + 0.006*\"сосновый\" + 0.006*\"билл\" + 0.005*\"домен\" + '\n",
      "  '0.004*\"баня\" + 0.004*\"пирог\"'),\n",
      " (5,\n",
      "  '0.065*\"топоним\" + 0.026*\"дубовский\" + 0.017*\"гвинея\" + 0.011*\"хутор\" + '\n",
      "  '0.007*\"андреевский\" + 0.007*\"плотина\" + 0.005*\"сергей\" + 0.004*\"старый\" + '\n",
      "  '0.004*\"юань\" + 0.003*\"волна\"'),\n",
      " (4,\n",
      "  '0.016*\"иордания\" + 0.015*\"виконт\" + 0.011*\"палестина\" + '\n",
      "  '0.010*\"палестинский\" + 0.009*\"леона\" + 0.009*\"виктория\" + 0.008*\"модуль\" + '\n",
      "  '0.008*\"эдвард\" + 0.008*\"комикс\" + 0.006*\"шрифт\"'),\n",
      " (3,\n",
      "  '0.021*\"граф\" + 0.013*\"литература\" + 0.011*\"графство\" + 0.009*\"брянский\" + '\n",
      "  '0.009*\"лихтенштейн\" + 0.009*\"i\" + 0.009*\"де\" + 0.008*\"ii\" + 0.008*\"юрий\" + '\n",
      "  '0.007*\"сын\"'),\n",
      " (2,\n",
      "  '0.010*\"пгт\" + 0.008*\"умерший\" + 0.007*\"гандбол\" + 0.006*\"спринт\" + '\n",
      "  '0.006*\"остановочный\" + 0.006*\"флотилия\" + 0.006*\"эстафета\" + 0.006*\"банк\" + '\n",
      "  '0.005*\"математик\" + 0.005*\"дивизия\"'),\n",
      " (1,\n",
      "  '0.008*\"чудновский\" + 0.006*\"летний\" + 0.003*\"4139\" + 0.003*\"фамилия\" + '\n",
      "  '0.003*\"смотреть\" + 0.003*\"семейство\" + 0.003*\"ни\" + 0.003*\"длина\" + '\n",
      "  '0.003*\"1992\" + 0.003*\"растение\"'),\n",
      " (0,\n",
      "  '0.006*\"житомирский\" + 0.003*\"летний\" + 0.002*\"почтовый\" + 0.002*\"км²\" + '\n",
      "  '0.002*\"индекс\" + 0.002*\"телефонный\" + 0.002*\"р-н\" + 0.002*\"остров\" + '\n",
      "  '0.002*\"ул\" + 0.002*\"зимний\"')]\n",
      "\n",
      "N-gram and Tfidf model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 171254.5062983833\n",
      "Coherence: 0.38636217702715103\n",
      "[(99,\n",
      "  '0.002*\"полигон\" + 0.001*\"северный_ирландия\" + 0.001*\"нил\" + '\n",
      "  '0.001*\"сельсовет\" + 0.001*\"танк\" + 0.001*\"кормовой\" + 0.000*\"брак\" + '\n",
      "  '0.000*\"личный_состав\" + 0.000*\"эскадренный_миноносец\" + 0.000*\"патриарх\"'),\n",
      " (98,\n",
      "  '0.000*\"матч\" + 0.000*\"сборная\" + 0.000*\"нация\" + 0.000*\"уэльс\" + '\n",
      "  '0.000*\"ирландия\" + 0.000*\"с_счёт\" + 0.000*\"выиграть\" + 0.000*\"турнир\" + '\n",
      "  '0.000*\"крым\" + 0.000*\"двор\"'),\n",
      " (97,\n",
      "  '0.000*\"северный_кавказ\" + 0.000*\"кавказский\" + 0.000*\"республика\" + '\n",
      "  '0.000*\"э\" + 0.000*\"до_н\" + 0.000*\"памятник\" + 0.000*\"грузинский\" + '\n",
      "  '0.000*\"чечня\" + 0.000*\"чеченский\" + 0.000*\"эпоха\"'),\n",
      " (95,\n",
      "  '0.001*\"быть_убить\" + 0.000*\"убийца\" + 0.000*\"бандит\" + 0.000*\"сергей\" + '\n",
      "  '0.000*\"группировка\" + 0.000*\"расстрелять\" + 0.000*\"владимир\" + '\n",
      "  '0.000*\"убийство\" + 0.000*\"завод\" + 0.000*\"предприятие\"'),\n",
      " (96,\n",
      "  '0.015*\"теорема\" + 0.008*\"квантовый\" + 0.002*\"пароход\" + 0.001*\"теория\" + '\n",
      "  '0.001*\"полузащитник\" + 0.001*\"железный\" + 0.001*\"особняк\" + 0.001*\"дом\" + '\n",
      "  '0.001*\"рудольф\" + 0.001*\"книга\"'),\n",
      " (94,\n",
      "  '0.000*\"дать_возможность\" + 0.000*\"доминик\" + 0.000*\"17_март\" + 0.000*\"for\" '\n",
      "  '+ 0.000*\"people\" + 0.000*\"st\" + 0.000*\"активист\" + 0.000*\"брисбен\" + '\n",
      "  '0.000*\"черта\" + 0.000*\"джеймс\"'),\n",
      " (93,\n",
      "  '0.001*\"хирург\" + 0.001*\"улица\" + 0.000*\"германия\" + 0.000*\"павлович\" + '\n",
      "  '0.000*\"герой_социалистический\" + 0.000*\"хирургический\" + 0.000*\"больница\" + '\n",
      "  '0.000*\"ханс\" + 0.000*\"ярославль\" + 0.000*\"океан\"'),\n",
      " (92,\n",
      "  '0.000*\"фрэнсис\" + 0.000*\"сержант\" + 0.000*\"дмитриевич\" + 0.000*\"гвардия\" + '\n",
      "  '0.000*\"5_июль\" + 0.000*\"посол\" + 0.000*\"окончить_курс\" + 0.000*\"россия\" + '\n",
      "  '0.000*\"присвоить_звание\" + 0.000*\"петроград\"'),\n",
      " (91,\n",
      "  '0.011*\"медный\" + 0.001*\"частица\" + 0.001*\"электроника\" + '\n",
      "  '0.001*\"транспортировка\" + 0.001*\"оркестр\" + 0.001*\"бригада\" + '\n",
      "  '0.001*\"инструмент\" + 0.000*\"вес\" + 0.000*\"мощный\" + 0.000*\"морской_пехота\"'),\n",
      " (90,\n",
      "  '0.006*\"стадион\" + 0.004*\"times\" + 0.003*\"29_декабрь\" + 0.001*\"трибуна\" + '\n",
      "  '0.001*\"радиоактивный\" + 0.001*\"фотография\" + 0.001*\"1964_год\" + '\n",
      "  '0.001*\"xvii\" + 0.001*\"фотограф\" + 0.001*\"new_york\"'),\n",
      " (9,\n",
      "  '0.006*\"петров\" + 0.005*\"франко\" + 0.004*\"прибрежный\" + 0.003*\"кировский\" + '\n",
      "  '0.003*\"функциональный\" + 0.003*\"обувь\" + 0.003*\"комбинат\" + '\n",
      "  '0.003*\"артефакт\" + 0.002*\"подбор\" + 0.002*\"чума\"'),\n",
      " (8,\n",
      "  '0.008*\"грузинский\" + 0.007*\"генри\" + 0.006*\"калужский_губерния\" + '\n",
      "  '0.006*\"калужский\" + 0.004*\"керамический\" + 0.003*\"1870\" + 0.002*\"механика\" '\n",
      "  '+ 0.002*\"стюарт\" + 0.002*\"луи\" + 0.002*\"модуль\"'),\n",
      " (7,\n",
      "  '0.012*\"аэропорт_аэропорт\" + 0.011*\"авиасообщение_с\" + '\n",
      "  '0.011*\"обеспечивать_регулярный\" + 0.010*\"ален\" + 0.010*\"ан-74\" + '\n",
      "  '0.010*\"вертолёт_весь\" + 0.009*\"региональный_центр\" + 0.009*\"монгольский\" + '\n",
      "  '0.008*\"ставка\" + 0.008*\"як-40\"'),\n",
      " (6,\n",
      "  '0.048*\"пункт\" + 0.013*\"хан\" + 0.011*\"атом\" + 0.009*\"кирилл\" + '\n",
      "  '0.006*\"слепой\" + 0.004*\"датский\" + 0.003*\"open\" + 0.003*\"юноша\" + '\n",
      "  '0.003*\"битый\" + 0.003*\"конгресс\"'),\n",
      " (5,\n",
      "  '0.083*\"ул\" + 0.044*\"попельнянский_район\" + 0.034*\"попельнянский_р-н\" + '\n",
      "  '0.024*\"житомирский_область\" + 0.010*\"нефть\" + 0.009*\"адрес_местный\" + '\n",
      "  '0.007*\"шина\" + 0.007*\"индонезия\" + 0.004*\"китайский_республика\" + '\n",
      "  '0.003*\"конфедерация\"'),\n",
      " (4,\n",
      "  '0.012*\"уругвай\" + 0.008*\"гай\" + 0.008*\"первый_лига\" + 0.008*\"албания\" + '\n",
      "  '0.007*\"уилсон\" + 0.007*\"мур\" + 0.005*\"иван\" + 0.004*\"симон\" + '\n",
      "  '0.004*\"харьковский_район\" + 0.003*\"монета\"'),\n",
      " (3,\n",
      "  '0.036*\"село\" + 0.025*\"на_расстояние\" + 0.024*\"харьковский_область\" + '\n",
      "  '0.022*\"сельский_совет\" + 0.020*\"топоним\" + 0.018*\"расположить_село\" + '\n",
      "  '0.016*\"течение\" + 0.016*\"река\" + 0.013*\"ниже_по\" + 0.011*\"выше_по\"'),\n",
      " (2,\n",
      "  '0.018*\"фамилия\" + 0.018*\"южный_корея\" + 0.009*\"снукер\" + 0.005*\"матрица\" + '\n",
      "  '0.004*\"шотландский\" + 0.004*\"национальный_чемпионат\" + 0.004*\"ибн\" + '\n",
      "  '0.004*\"фильм\" + 0.004*\"дэвис\" + 0.003*\"название\"'),\n",
      " (1,\n",
      "  '0.007*\"романовский_район\" + 0.004*\"—_4146\" + 0.002*\"uss\" + '\n",
      "  '0.002*\"подсемейство\" + 0.002*\"чел\" + 0.002*\"уэльс\" + 0.002*\"банк\" + '\n",
      "  '0.002*\"белокалитвинский_район\" + 0.002*\"почтовый\" + 0.002*\"строй\"'),\n",
      " (0,\n",
      "  '0.005*\"житомирский_область\" + 0.002*\"на_украина\" + 0.002*\"год_составлять\" + '\n",
      "  '0.002*\"перепись_2001\" + 0.002*\"население_по\" + 0.002*\"км²\" + '\n",
      "  '0.002*\"за_свой\" + 0.002*\"индекс_—\" + 0.002*\"человек_почтовый\" + '\n",
      "  '0.002*\"летний_олимпийский\"')]\n"
     ]
    }
   ],
   "source": [
    "fit_all_models(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По оценке метриками и \"на глаз\" самые хорошие результаты получаются у чистой модели. Чуть хуже проявляет себя модель с н-граммами. У моделей, где есть TfIdf получаются наихудшие результаты, но тем не менее, среди этих результатов тоже можно выделить какую-то обшую тему. Вероятно, такие результаты связаны с тем, что корпус для обучения взят не такой большой. Также уменьшение количества тем улучшает качество моделирование по метрикам."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
