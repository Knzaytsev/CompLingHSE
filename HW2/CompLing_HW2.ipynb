{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razdel in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Для каких стан является эталоном современная с...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В шапке были ссылки на инфу по текущему фильму...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РА...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ебать тебя разносит, шизик.\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Обосрался, сиди обтекай\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n",
       "5  Для каких стан является эталоном современная с...    1.0\n",
       "6  В шапке были ссылки на инфу по текущему фильму...    0.0\n",
       "7  УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РА...    1.0\n",
       "8                      Ебать тебя разносит, шизик.\\n    1.0\n",
       "9                          Обосрался, сиди обтекай\\n    1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(text):\n",
    "    tokens = list(tokenize(text))\n",
    "    return [token.text for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_vectorizer = CountVectorizer()\n",
    "razdel_vectorizer = CountVectorizer(tokenizer=get_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_by_vectorizer(comments, vectorizer, is_transform=True):\n",
    "    if is_transform:\n",
    "        return vectorizer.fit_transform(comments)\n",
    "    return vectorizer.transform(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_quality(name_vectorizer, vectorizer, model, train, test):\n",
    "    print(f'Векторайзер {name_vectorizer}')\n",
    "    X = get_X_by_vectorizer(train.comment, vectorizer)\n",
    "    y = train.toxic.values\n",
    "\n",
    "    X_test = get_X_by_vectorizer(test.comment, vectorizer, False)\n",
    "    y_test = test.toxic.values\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    print(classification_report(y_test, preds, zero_division=0))\n",
    "    print(30*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторайзер default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.94      0.90      2878\n",
      "         1.0       0.85      0.69      0.76      1446\n",
      "\n",
      "    accuracy                           0.86      4324\n",
      "   macro avg       0.86      0.82      0.83      4324\n",
      "weighted avg       0.86      0.86      0.85      4324\n",
      "\n",
      "------------------------------\n",
      "Векторайзер razdel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.90      2878\n",
      "         1.0       0.85      0.72      0.78      1446\n",
      "\n",
      "    accuracy                           0.86      4324\n",
      "   macro avg       0.86      0.83      0.84      4324\n",
      "weighted avg       0.86      0.86      0.86      4324\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "vectorizers = [('default', default_vectorizer), ('razdel', razdel_vectorizer)]\n",
    "for i in range(len(vectorizers)):\n",
    "    name_vectorizer = vectorizers[i][0]\n",
    "    vectorizer = vectorizers[i][1]\n",
    "    compute_model_quality(name_vectorizer, vectorizer, LogisticRegression(), train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом в обоих случаях векторайзеры показывают одинаковые результаты, но стоит отметить, что иногда модель на векторайзере на разделе получает чуть лучшие результаты, чем на дефолтном."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = np.array([\n",
    "                [1, 1, 1, 0, 0, 0],\n",
    "                [1, 1, 1, 0, 0, 0],\n",
    "                [3, 0, 1, 1, 0, 0],\n",
    "                [1, 0, 0, 1, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>я и ты</th>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.132647</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ты и я</th>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.132647</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>я, я и только я</th>\n",
       "      <td>0.058146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04437</td>\n",
       "      <td>0.079588</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>только не я</th>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.132647</td>\n",
       "      <td>0.23299</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>он</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        я        ты        и    только       не       он\n",
       "я и ты           0.032303  0.132647  0.07395  0.000000  0.00000  0.00000\n",
       "ты и я           0.032303  0.132647  0.07395  0.000000  0.00000  0.00000\n",
       "я, я и только я  0.058146  0.000000  0.04437  0.079588  0.00000  0.00000\n",
       "только не я      0.032303  0.000000  0.00000  0.132647  0.23299  0.00000\n",
       "он               0.000000  0.000000  0.00000  0.000000  0.00000  0.69897"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = data_table.shape[0]\n",
    "result = []\n",
    "\n",
    "for sent in data_table:\n",
    "    norm_sent = []\n",
    "    for word in range(len(sent)):\n",
    "        norm_sent.append(sent[word] / sent.sum() * np.log10(N / np.count_nonzero(data_table.T[word])))\n",
    "    result.append(norm_sent)\n",
    "    \n",
    "result_table = pd.DataFrame(data=result, columns=['я', 'ты', 'и', 'только', 'не', 'он'], \n",
    "                           index=['я и ты', 'ты и я', 'я, я и только я', 'только не я', 'он'])\n",
    "result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требования к классификаторам:   \n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_stopwords():\n",
    "    sw = stopwords.words('russian')\n",
    "    sw.extend(['это', 'например', 'тебе'])\n",
    "    return sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_models(name_vectorizer, name_model, vectorizer, model, train, test):\n",
    "    print(f'Модель {name_model} с векторайзером {name_vectorizer}')\n",
    "    \n",
    "    X = get_X_by_vectorizer(train.clear_comment, vectorizer)\n",
    "    y = train.toxic.values\n",
    "\n",
    "    X_test = get_X_by_vectorizer(test.clear_comment, vectorizer, False)\n",
    "    y_test = test.toxic.values\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    print('Качество модели')\n",
    "    print(classification_report(y_test, preds, zero_division=0))\n",
    "    \n",
    "    probas = np.array(model.predict_proba(X_test))[:, 1]\n",
    "    sorted_comments = sorted(zip(probas, test.clear_comment), reverse=True)\n",
    "\n",
    "    print('Самые токсичные тексты')\n",
    "    pprint([x[1] for x in sorted_comments][:10])\n",
    "    print(40*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = 0.6\n",
    "min_df = 2\n",
    "ngram_range = (1, 2)\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words=get_init_stopwords(), \n",
    "                                   max_df=max_df, min_df=min_df, \n",
    "                                   tokenizer=get_token, ngram_range=ngram_range)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=get_token, \n",
    "                                   stop_words=get_init_stopwords(), \n",
    "                                   ngram_range=ngram_range, \n",
    "                                   max_df=max_df, min_df=min_df,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train['clear_comment'] = train.comment.str.replace('[^\\w\\s]', '')\n",
    "test['clear_comment'] = test.comment.str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель DecisionTreeClassifier с векторайзером CountVectorizer\n",
      "Качество модели\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.81      0.82      2878\n",
      "         1.0       0.64      0.66      0.65      1446\n",
      "\n",
      "    accuracy                           0.76      4324\n",
      "   macro avg       0.74      0.74      0.74      4324\n",
      "weighted avg       0.77      0.76      0.77      4324\n",
      "\n",
      "Самые токсичные тексты\n",
      "['чувак я хоть и не особый любитель каверов да и всей теперешной музыкикоторую '\n",
      " 'я уже не слушаю ты при своём исполнении system of a dawn  Chop Suey просто '\n",
      " 'понравился твоим русским исполнением  плюсярю тебе бро\\n',\n",
      " 'чем больше бояр тем меньше холопов на одного барина какая странная '\n",
      " 'математика следовательно старшие бояре будут чморить младших бояр так как '\n",
      " 'холопов мало\\n',\n",
      " 'хуйца пососи блядина лахтинская иди на завод сосать хуй за 15К под твои '\n",
      " 'потребности как раз\\n',\n",
      " 'хотят завезти Епта они и так приезжают И даже больше Ну даст им вова паспорт '\n",
      " 'в упрощенном порядке  что для тебя изменится Ты что у чурок паспорт '\n",
      " 'спрашиваешь\\n',\n",
      " 'хорош пиздить фотки с багини\\n',\n",
      " 'фотографии президента РФ в фашистской форме Если Путин целенаправленно '\n",
      " 'уничтожает русский народ делает из него народ второго сорта то кто он\\n',\n",
      " 'фаг про всяких шлюх это про блогеров\\n',\n",
      " 'украинец пидорашка это известный факт',\n",
      " 'у меня до сих пор они есть только предыдущая модель с диском а не кнопками\\n',\n",
      " 'у вас хоть под балконом у меня балкон полностью засран полностью эти твари '\n",
      " 'засрали его на НЕДЕЛЮ тупо места чистого нет хз в чем дело я их не '\n",
      " 'подкармливал вовсе\\n']\n",
      "----------------------------------------\n",
      "Модель RandomForestClassifier с векторайзером TfidfVectorizer\n",
      "Качество модели\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.87      0.85      2878\n",
      "         1.0       0.72      0.67      0.69      1446\n",
      "\n",
      "    accuracy                           0.80      4324\n",
      "   macro avg       0.78      0.77      0.77      4324\n",
      "weighted avg       0.80      0.80      0.80      4324\n",
      "\n",
      "Самые токсичные тексты\n",
      "['старый даун всрал все пишов он нахуй я за двощ дефаю\\n',\n",
      " 'если на борде не будет хохлов то не будет про них постов\\n',\n",
      " 'Пидорашек выселить а не хохлов Ты сам себе противоречишь дурачок\\n',\n",
      " 'И до хохлов добралось\\n',\n",
      " 'Всех же так волнуетчто там у хохлов\\n',\n",
      " 'Так это не фантазии дебил это вывод с ваших же постов\\n',\n",
      " 'Хохол с гранатой в дупе это уже ДИВЕРСАНТ\\n',\n",
      " 'Да хохол ты за все заплатишь\\n',\n",
      " 'Зачем ты пишешь хуйню дегенерат Поцелуй в губы  поцелую в засос\\n',\n",
      " 'пук пук пук пук МАЛОЛЕТНИЙ ДЕБИЛ НАСРАЛЬНЕНОК ОПЯТЬ НАВАЛИЛ ГАВНА В '\n",
      " 'КАМЕНТАХ\\n']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vectorizers = [('CountVectorizer', count_vectorizer), ('TfidfVectorizer', tfidf_vectorizer)]\n",
    "models = [('DecisionTreeClassifier', DecisionTreeClassifier(criterion='entropy', min_samples_split=3, \n",
    "                                                            min_samples_leaf=3, \n",
    "                                                            max_depth=10000, max_leaf_nodes=10000)),\n",
    "          ('RandomForestClassifier', RandomForestClassifier(criterion='entropy', n_estimators=500))]\n",
    "               \n",
    "for i in range(len(vectorizers)):\n",
    "    name_model = models[i][0]\n",
    "    model = models[i][1]\n",
    "    name_vectorizer = vectorizers[i][0]\n",
    "    vectorizer = vectorizers[i][1]\n",
    "    process_models(name_vectorizer, name_model, vectorizer, model, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-первых, как можно заметить, случайный лес работает намного лучше, чем дерево решений с кучей настроенных вручную параметров. Возможно это из-за используемого векторайзера, но я думаю, что это даёт всё равно небольшой прирост. Во-вторых, в случае с деревом в самые токсичные тексты попадают и не совсем токсичные. В случае со случайным лесом таких ситуаций намного меньше (все тексты токсичные из 10 самых токсичных). В-третьих, полноценно тексты всё же отличаются между собой, однако среди них есть общее, которое выражается в обильном использовании различных ругательств, что маркирует тексты как токсичные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=5):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0] if type(clf) in \n",
    "                                [LogisticRegression, MultinomialNB] else clf.feature_importances_, feature_names))\n",
    "\n",
    "    top = coefs_with_fns[:-(n + 1):-1]\n",
    "    for (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\" % (coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "                LogisticRegression(),\n",
    "                MultinomialNB(),\n",
    "                RandomForestClassifier(),\n",
    "                DecisionTreeClassifier()]\n",
    "vectorizers = [\n",
    "                count_vectorizer,\n",
    "                tfidf_vectorizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------CountVectorizer--------------------\n",
      "--------------------LogisticRegression--------------------\n",
      "\t2.7975\tхохлов         \n",
      "\t2.7084\tхохлы          \n",
      "\t2.1199\tнахуй          \n",
      "\t2.1053\tдебил          \n",
      "\t1.9164\tтупые          \n",
      "--------------------MultinomialNB--------------------\n",
      "\t-5.6125\tпросто         \n",
      "\t-6.2037\tвсё            \n",
      "\t-6.3186\tвообще         \n",
      "\t-6.3361\tпочему         \n",
      "\t-6.4096\tещё            \n",
      "--------------------RandomForestClassifier--------------------\n",
      "\t0.0092\tхохлы          \n",
      "\t0.0075\tхохлов         \n",
      "\t0.0070\tнахуй          \n",
      "\t0.0060\tочень          \n",
      "\t0.0043\tбыдло          \n",
      "--------------------DecisionTreeClassifier--------------------\n",
      "\t0.0165\tхохлы          \n",
      "\t0.0132\tнахуй          \n",
      "\t0.0118\tхохлов         \n",
      "\t0.0088\tочень          \n",
      "\t0.0070\tблядь          \n",
      "--------------------TfidfVectorizer--------------------\n",
      "--------------------LogisticRegression--------------------\n",
      "\t4.2503\tхохлы          \n",
      "\t3.9383\tхохлов         \n",
      "\t3.7292\tнахуй          \n",
      "\t2.8453\tпиздец         \n",
      "\t2.7694\tблядь          \n",
      "--------------------MultinomialNB--------------------\n",
      "\t-7.0393\tпросто         \n",
      "\t-7.0888\tхохлы          \n",
      "\t-7.2173\tпочему         \n",
      "\t-7.2431\tхохлов         \n",
      "\t-7.3611\tнахуй          \n",
      "--------------------RandomForestClassifier--------------------\n",
      "\t0.0099\tхохлы          \n",
      "\t0.0080\tхохлов         \n",
      "\t0.0070\tнахуй          \n",
      "\t0.0067\tочень          \n",
      "\t0.0045\tблядь          \n",
      "--------------------DecisionTreeClassifier--------------------\n",
      "\t0.0165\tхохлы          \n",
      "\t0.0133\tнахуй          \n",
      "\t0.0118\tхохлов         \n",
      "\t0.0097\tочень          \n",
      "\t0.0079\tблядь          \n"
     ]
    }
   ],
   "source": [
    "for vectorizer in vectorizers:\n",
    "    print(20*'-' + vectorizer.__class__.__name__ + 20*'-')\n",
    "    \n",
    "    X = get_X_by_vectorizer(train.clear_comment, vectorizer)\n",
    "    y = train.toxic.values\n",
    "\n",
    "    X_test = get_X_by_vectorizer(test.clear_comment, vectorizer, False)\n",
    "    y_test = test.toxic.values\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        print(20*'-' + classifier.__class__.__name__ + 20*'-')\n",
    "        \n",
    "        classifier.fit(X, y)\n",
    "        show_most_informative_features(vectorizer, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам можно заключить следующее. TfidfVectorizer работает намного лучше, чем CountVectorizer. Логистическая регрессия показывает лучшие результаты по сравнению с другими классификаторами. Байесовский алгоритм показывает наихудшие результаты. В целом у каждого классификатора результаты одинаковы. Самые токсичные слова - это как раз те, которые обозначают какое-то ругательное слово, мат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
